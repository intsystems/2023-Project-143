\documentclass{beamer}
\usepackage{bbm}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amscd,amssymb}
\usepackage{amsfonts,amsmath,array}
\usepackage[dvips]{graphicx}
\usepackage{longtable,wrapfig}
\usepackage{graphicx}
\usepackage{sidecap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}


%beamer  theme's used to be here :)
%\usetheme{mipt_beamer}
\usetheme{Boadilla}
\title{Метрический анализ пространства параметров глубоких нейросетей.}
\author{Насыров~Э.Р.}
\date{March 14, 2045} %\today

\institute{МФТИ}
\date{\today}

\begin{document}
\frame{\titlepage}

\begin{frame}{Содержание}
    \begin{tableofcontents}
        \section{Введение}
        \section{Методы улучшения обучения}
            %\subsection{Актуальность темы}
            %\subsection{Задача выделения сообществ}
            %\subsection{Алгоритмы выделения сообществ в графах}
            %\subsection{Лувенский алгоритм}
            %\subsection{Алгоритмы выделения сообществ в гиперграфах}
        \section{Мотивация}
        \section{Постановка задачи}
        %\section{Постановка задачи}
        %    \subsection{Цели и задачи}
        %    \subsection{Метрики объединения сообществ}
        %\section{Результаты экспериментов}
        %\section{Выводы}
        \section{Используемые модели}
        \section{Данные}
        \section{Планируемые результаты}
        
            
    \end{tableofcontents}
\end{frame}


\begin{frame}{Введение}
\begin{columns}
\column{0.5\textwidth}
\begin{itemize}
        \item Высокоразмерные данные - видео, звук - избыточны.
        \item Модели тяжело обучаются на избыточных данных, часто переобучаются.
        \item Нужно бороться с избыточностью и переобучением.
    \end{itemize}
    
    
\column{0.5\textwidth}
\begin{figure}
\includegraphics[scale=0.4]{overfit.png}
\caption{Переобучение.}
\end{figure}

\end{columns}
\end{frame}


\begin{frame}{Методы улучшения обучения}
\begin{itemize}

    \item Методы снижения размерности входных данных:
        \begin{itemize}
            \item PCA
            \item Quadratic Programming Feature selection
            \item Neural Autoencoders
        \end{itemize}

    \item Выбор оптимальной структуры модели:
        \begin{itemize}
            \item Optimal Brain Surgeon
            \item Correlational analysis
            \item Weights freezing
        \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Мотивация}
\begin{itemize}

    \item В предыдущих работах параметры модели $\mathbf{w}$ рассматриваются как отдельные скаляры.
    \item Не учтена простая структура нейросети -  композиция линейных и простых нелинейных функций.
    \item Составной блок нейросети:
        \[y=\sigma(\mathsf{W}x + b),\\ \ y, b \in \mathbb{R}^m, \ x \in \mathbb{R}^n, \ \mathsf{W} \in \mathbb{R}^{m \times n}, \ \sigma: \mathbb{R} \to \mathbb{R}.\]
    \item В нашей работе будут исследованы не отдельные жлементы $\mathsf{W}$, а ее строки $\mathbf{w}_i$, которые в нейросети называют \textit{нейронами}:

    \[\mathsf{W} = \begin{pmatrix}
\mathbf{w}_1^{\mathsf{T}}\\
\dots\\
\mathbf{w}_m^{\mathsf{T}}\\
\end{pmatrix}.\]
\end{itemize}
\end{frame}




\begin{frame}{Постановка задачи}
\begin{itemize}
    \item Дан временной ряд  $\mathbf{x} = [x_1, \dots, x_N]^{\mathsf{T}}, x_i \in \mathbb{R}$, ширина окна $n$.
    \item Точка $\mathbf{x}_t = [x_t, \dots, x_{t + n - 1}]^{\mathsf{T}}$ - точка фазовой траектории временного ряда в траекторном пространстве $\mathbb{H}_{\mathbf{x}} \subset \mathbb{R}^n$.
    \item Предположение: точка фазовой траектории распределена               \textit{нормально} в фазовом пространстве.
    \item Тогда параметры обученной нейросети будут случайными.
\end{itemize}
\end{frame}


\begin{frame}{Постановка задачи}
\begin{itemize}
    \item Для каждого вектора-параметра $\mathbf{w}_i$ оцениваем его матожидание $\mathbf{e_1} = \mathsf{E}\mathbs{w}_i$ и ковариационную матрицу $\mathsf{D}_i = cov(\mathbf{w}_i)$.
    \item Для каждого вектора вычисляем его $90\%$ вероятностную область и траекторном пространстве.
    \item Проецируем на 2-х мерное (3-х) мерное пространство.
    \item Визуализируем результаты.
\end{itemize}

\begin{columns}

\column{0.5\textwidth}
    \begin{figure}
    \includegraphics[scale=0.25]{gaussian_mixture.jpg}
    \caption{Смесь гауссианов трех 2-х мерных векторов.}
    \end{figure}

\column{0.5\textwidth}
    \begin{figure}
    \includegraphics[scale=0.37]{gaussian_conf_area.jpg}
    \caption{Доверительные области 3-х мерных векторов.}
    \end{figure}

\end{columns}
\end{frame}




\begin{frame}{Формальная постановка задачи}
\begin{itemize}
    \item Решается задача авторегрессионного декодирования.
    \item Обозначим множество всех одномерных временных рядов через $\mathbb{S}$: \[\mathbb{S} = \bigcup\limits_{n=1}^{+\infty}\{[s_1, \dots, s_n] \in \mathbb{R}^{n}\}.\]
    \item Прогностическая модель $\mathbf{f}^{\mathsf{AR}}: \mathbb{S} \to \mathbb{R}$ предсказывает следующее значение временного ряда по предыдущим.
    \item Модель $f = f(\mathbf{w}, \mathbf{s}), \mathbf{w} \in \mathbb{W}, \mathbf{s}=[s_1, \dots, s_t]\in \mathbb{R}^t$ выбирается из некоего параметрического семейства.
Параметры модели выбираются таким образом, чтобы минимизировать функцию ошибки $S=S(\mathbf{w}|\mathbf{s},f)$:
$$
\mathbf{w^*} = \arg \min \limits_{\mathbf{w} \in \mathbb{W}} S(\mathbf{w}|\mathbf{s},f).
$$


В работе будет использоваться функция ошибки MSE, то есть 
$$
S(\mathbf{w}|\mathbf{s},f) = \sum\limits_{t=h+1}^{T}(\mathbf{s}_t - \hat{\mathbf{s}}_t)^2.
$$.
\end{itemize}
\begin{figure}
\includegraphics[scale=0.2]{hyper_proj.jpg}
\caption{Кликовая проекция гиперграфа.}
\end{figure}
\end{frame}



\begin{frame}{Используемые модели}
    \begin{itemize}
        \item Нелинейный PCA:
            \[\mathbf{f}(x) = \sigma(w^{\mathsf{T}}\cdot \sigma(W^{\mathsf{T}}x + b_1) + b_2)\]
            \[x \in \mathbb{R}^{h}, \ W \in \mathbb{R}^{h \times d}, \ w \in \mathbb{R}^d: w^Tw=1, WW^T=I.\]

        \item RNN:
            \[ h_t = \sigma(W \cdot h_{t-1} + V \cdot \mathbf{x}_t),\]
            \[ s_{t+1} = tanh(w_o^{\mathsf{T}} \cdot h_t)\]
    \end{itemize}
\end{frame}

\begin{frame}{Данные}
    \begin{itemize}
        \item Синтетические: зашумленный $\sin$.
        \item Данные акселерометра.
        \item Данные активности мозга во время прослушивания звуковой дорожки.
    \end{itemize}

    \begin{figure}
    \includegraphics[scale=0.7]{acsel.jpg}
    \caption{Показания аксеелерометра во время подъема по лестнице.}
    \end{figure}
\end{frame}


\begin{frame}{Планируемые результаты}
\begin{itemize}
    \item Провести метрический анализ признакового пространства нейронов сети.
    \item Научиться выявлять ненужные нейроны.
    \item Научиться выделять структуру сообществ в нейронах.
    \item Преобразовать признаковое пространство, объединяя сильно скореллированные нейроны в новые.
    \item Разработать алгоритм снижения размерности признакового пространства.
    \item Ускорить обучение известных моделей работы с временными рядами, улучшить их качество, увеличить стабильность.
\end{itemize}
\end{frame}
    
\end{document}