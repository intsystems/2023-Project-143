{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a6fcbb6",
   "metadata": {},
   "source": [
    "# Исследование MyAdamW и AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449d737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e0c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124, 112) (8124,)\n",
      "[-1.  1.  1. ...  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = \"mushrooms.txt\" \n",
    "data = load_svmlight_file(dataset)\n",
    "X, y = data[0].toarray(), data[1]\n",
    "n, d = X.shape\n",
    "print(X.shape, y.shape)\n",
    "y = y*2 - 3\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81832d59",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48c396dd",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b600352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Wine.csv')\n",
    "data['color'] = data['color'].apply(lambda x: 1 if x == 'red' else -1)\n",
    "X = data.drop(columns='color').to_numpy()\n",
    "y = data['color'].to_numpy()\n",
    "X = np.array(X, dtype=np.float64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1374194f",
   "metadata": {},
   "source": [
    "### Water PROBABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99e51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('water_potability.csv')\n",
    "data = data.dropna(axis=0)\n",
    "X = data.drop(columns='Potability').to_numpy()\n",
    "X = np.array(X, dtype=np.float64)\n",
    "y = data['Potability'].to_numpy()\n",
    "y = np.array(y, dtype=np.float64)\n",
    "y = y * 2 - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "062c431c",
   "metadata": {},
   "source": [
    "### Diabete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eef618ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data = data.dropna(axis=0)\n",
    "X = data.drop(columns='1').to_numpy()\n",
    "X = np.array(X, dtype=np.float64)\n",
    "y = data['1'].to_numpy()\n",
    "y = np.array(y, dtype=np.float64)\n",
    "y = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff668073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6499, 112)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adeeaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d08eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import lib\n",
    "reload(lib)\n",
    "from lib  import MyLogregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6009526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models_acc_error(*args):\n",
    "    _, ax = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    title = args[1]\n",
    "    ax[0, 0].set_title(f\"Логарифм ошибки от номера итерации ($error = || {title} ||$)\")\n",
    "    ax[0, 0].set_xlabel(\"Номер итерации\")\n",
    "    ax[0, 0].set_ylabel(\"Логарифм ошибки\")\n",
    "    \n",
    "    ax[0, 1].set_title(f\"Логарифм ошибки от времени ($error = || {title}||$)\")\n",
    "    ax[0, 1].set_xlabel(\"Время, с\")\n",
    "    ax[0, 1].set_ylabel(\"Логарифм ошибки\")\n",
    "    \n",
    "    ax[1, 0].set_title(\"Точность от номера итерации\")\n",
    "    ax[1, 0].set_xlabel(\"Номер итерации\")\n",
    "    ax[1, 0].set_ylabel(\"Точность\")\n",
    "    \n",
    "    ax[1, 1].set_title(\"Точность от времени\")\n",
    "    ax[1, 1].set_xlabel(\"Время, с\")\n",
    "    ax[1, 1].set_ylabel(\"Точность\")\n",
    "    for model in args[0]:\n",
    "\n",
    "        y = np.array(model.get_errors())\n",
    "        x = np.linspace(0, len(y), len(y))\n",
    "        ax[0, 0].plot(x, np.log(y), label=model.get_name())\n",
    "        x = np.array(model.get_time())\n",
    "        ax[0, 1].plot(x, np.log(y), label=model.get_name())\n",
    "        if (model.get_name()[0:5] == \"AdamW\"):\n",
    "            y = np.array(model._error_adamw)\n",
    "            x = np.linspace(0, len(y), len(y))\n",
    "            ax[0, 0].plot(x, np.log(y), label=model.get_name() + '_true')\n",
    "            x = np.array(model.get_time())\n",
    "            ax[0, 1].plot(x, np.log(y), label=model.get_name() + '_true')\n",
    "\n",
    "        y = np.array(model.get_accuracy())\n",
    "        x = np.linspace(0, len(y), len(y))\n",
    "        ax[1, 0].plot(x, y, label=model.get_name())\n",
    "        x = np.array(model.get_time())\n",
    "        ax[1, 1].plot(x, y, label=model.get_name())\n",
    "\n",
    "\n",
    "    legend_box = ax[1, 1].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "    legend_box = ax[1, 0].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "    legend_box = ax[0, 1].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "    legend_box = ax[0, 0].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "\n",
    "def plot_models_acc_error2(*args):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "    title = args[1]\n",
    "    ax[0].set_title(f\"Логарифм ошибки от номера итерации ($error = || {title} ||$)\")\n",
    "    ax[0].set_xlabel(\"Номер итерации\")\n",
    "    ax[0].set_ylabel(\"Логарифм ошибки\")\n",
    "    \n",
    "    ax[1].set_title(\"Точность от номера итерации\")\n",
    "    ax[1].set_xlabel(\"Номер итерации\")\n",
    "    ax[1].set_ylabel(\"Точность\")\n",
    "\n",
    "    for model in args[0]:\n",
    "\n",
    "        if (model.get_name()[0:5] == \"AdamW\"):\n",
    "            y = np.array(model.get_errors())\n",
    "            x = np.linspace(0, len(y), len(y))\n",
    "            ax[0].plot(x, np.log(y), label=model.get_name() + '[ $\\\\nabla f + \\\\nabla r$ ]')\n",
    "            \n",
    "            y = np.array(model._error_adamw)\n",
    "            x = np.linspace(0, len(y), len(y))\n",
    "            ax[0].plot(x, np.log(y), label=model.get_name() + '[ $\\\\nabla f + \\\\nabla r D_t$ ]')\n",
    "        else:\n",
    "            y = np.array(model.get_errors())\n",
    "            x = np.linspace(0, len(y), len(y))\n",
    "            ax[0].plot(x, np.log(y), label=model.get_name())\n",
    "\n",
    "        y = np.array(model.get_accuracy())\n",
    "        x = np.linspace(0, len(y), len(y))\n",
    "        ax[1].plot(x, y, label=model.get_name())\n",
    "        \n",
    "    legend_box = ax[1].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")\n",
    "\n",
    "    legend_box = ax[0].legend(framealpha=1).get_frame()\n",
    "    legend_box.set_facecolor(\"white\")\n",
    "    legend_box.set_edgecolor(\"black\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89c31f8a",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13738025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gd_models(X_train, y_train, X_test, y_test, learning_rates=np.linspace(1, 0.0001, 5)):\n",
    "    gd_models = []\n",
    "    for lr in learning_rates:\n",
    "        GD = MyLogregression(iter=1000, lr_func=lambda w: lr, name=\"GD\", label=\"GD(%0.4f)\" % lr)\n",
    "        GD.fit(X_train, y_train, X_test, y_test)\n",
    "        gd_models.append(GD)\n",
    "    return gd_models\n",
    "\n",
    "def get_adamw_models(X_train, y_train, X_test, y_test, \\\n",
    "                    learning_rates=[0.1, 0.05, 0.01], weight_decays=[0.1, 0.05, 0.005]):\n",
    "    adamw_models = []\n",
    "    for lr in learning_rates:\n",
    "        for wd in weight_decays:\n",
    "            AdamW = MyLogregression(iter=1000, lr_func=lambda w: lr, name=\"AdamW\", label=f\"AdamW({lr}, {wd})\", betas=[0.99, 0.999], l2_coef=wd)\n",
    "            AdamW.fit(X_train, y_train, X_test, y_test)    \n",
    "            adamw_models.append(AdamW)\n",
    "    return adamw_models\n",
    "\n",
    "def get_adaml2_models(X_train, y_train, X_test, y_test, \\\n",
    "                      learning_rates=[0.1, 0.05, 0.01], weight_decays=[0.1, 0.05, 0.005]):\n",
    "    adaml2_models = []\n",
    "    for lr in learning_rates:\n",
    "        for wd in weight_decays:\n",
    "            Adaml2 = MyLogregression(iter=1000, lr_func=lambda w: lr, name=\"AdamL2\", label=f\"AdamL2({lr}, {wd})\", betas=[0.99, 0.999], l2_coef=wd)\n",
    "            Adaml2.fit(X_train, y_train, X_test, y_test)    \n",
    "            adaml2_models.append(Adaml2)\n",
    "    return adaml2_models\n",
    "\n",
    "def get_oasis_models(X_train, y_train, X_test, y_test, \\\n",
    "                    learning_rates=[0.1, 0.05, 0.01], weight_decays=[0.1, 0.05, 0.005]):\n",
    "    oasis_models = []\n",
    "    for lr in learning_rates:\n",
    "        for wd in weight_decays:\n",
    "            OASIS = MyLogregression(iter=1000, lr_func=lambda w: lr, name=\"OASIS\", label=f\"OASIS({lr}, {wd})\", betas=[0.99, 0.999], l2_coef=wd)\n",
    "            OASIS.fit(X_train, y_train, X_test, y_test)    \n",
    "            oasis_models.append(OASIS)\n",
    "    return oasis_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7820eff8",
   "metadata": {},
   "source": [
    "### AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ef0bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m learning_rates \u001b[39m=\u001b[39m [\u001b[39m0.1\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.01\u001b[39m]\n\u001b[0;32m      2\u001b[0m weight_decays \u001b[39m=\u001b[39m [\u001b[39m0.1\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.005\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m adamw_models \u001b[39m=\u001b[39m get_adamw_models(X_train, y_train, X_test, y_test, learning_rates, weight_decays)\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mget_adamw_models\u001b[1;34m(X_train, y_train, X_test, y_test, learning_rates, weight_decays)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[39mfor\u001b[39;00m wd \u001b[39min\u001b[39;00m weight_decays:\n\u001b[0;32m     14\u001b[0m         AdamW \u001b[39m=\u001b[39m MyLogregression(\u001b[39miter\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, lr_func\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m w: lr, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAdamW\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAdamW(\u001b[39m\u001b[39m{\u001b[39;00mlr\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mwd\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, betas\u001b[39m=\u001b[39m[\u001b[39m0.99\u001b[39m, \u001b[39m0.999\u001b[39m], l2_coef\u001b[39m=\u001b[39mwd)\n\u001b[1;32m---> 15\u001b[0m         AdamW\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_test, y_test)    \n\u001b[0;32m     16\u001b[0m         adamw_models\u001b[39m.\u001b[39mappend(AdamW)\n\u001b[0;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m adamw_models\n",
      "File \u001b[1;32mw:\\MIPT\\6_sem\\article local\\lib.py:89\u001b[0m, in \u001b[0;36mMyLogregression.fit\u001b[1;34m(self, X, y, X_test, y_test)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time       \u001b[39m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i          \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__function, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grad_function, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lr_func)\n\u001b[0;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mw:\\MIPT\\6_sem\\article local\\lib.py:164\u001b[0m, in \u001b[0;36mMyLogregression.__AdamW\u001b[1;34m(self, f, grad_f, w0, lr)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter):\n\u001b[0;32m    163\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 164\u001b[0m     grad \u001b[39m=\u001b[39m grad_f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_w)\n\u001b[0;32m    166\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_betas[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m m \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_betas[\u001b[39m0\u001b[39m]) \u001b[39m*\u001b[39m grad\n\u001b[0;32m    167\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_betas[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m v \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_betas[\u001b[39m1\u001b[39m]) \u001b[39m*\u001b[39m (grad \u001b[39m*\u001b[39m grad)\n",
      "File \u001b[1;32mw:\\MIPT\\6_sem\\article local\\lib.py:46\u001b[0m, in \u001b[0;36mMyLogregression.__grad_function\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train)):            \n\u001b[0;32m     45\u001b[0m     up \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train[i] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_X_train[i] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train[i] \u001b[39m*\u001b[39m w \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_X_train[i])\n\u001b[1;32m---> 46\u001b[0m     down \u001b[39m=\u001b[39m n \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mexp(\u001b[39m-\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_y_train[i] \u001b[39m*\u001b[39;49m w \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_X_train[i]))\n\u001b[0;32m     47\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m  \u001b[39m-\u001b[39m up\u001b[39m/\u001b[39mdown\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.05, 0.01]\n",
    "weight_decays = [0.1, 0.05, 0.005]\n",
    "adamw_models = get_adamw_models(X_train, y_train, X_test, y_test, learning_rates, weight_decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf27304",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_acc_error2(adamw_models[0:5], '\\\\nabla f(x)')\n",
    "plot_models_acc_error2(adamw_models[5:], '\\\\nabla f(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90c11ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.05, 0.01]\n",
    "weight_decays = [0.1, 0.05, 0.005]\n",
    "adaml2_models = get_adaml2_models(X_train, y_train, X_test, y_test, learning_rates, weight_decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7694954",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.05, 0.01]\n",
    "weight_decays = [0.1, 0.05, 0.005]\n",
    "gd_models = get_gd_models(X_train, y_train, X_test, y_test, learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.05, 0.01]\n",
    "weight_decays = [0.1, 0.05, 0.005]\n",
    "oasis_models = get_oasis_models(X_train, y_train, X_test, y_test, learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829715af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_acc_error2(adaml2_models[1:], '\\\\nabla f(x) + \\\\nabla r(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aef12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_acc_error(oasis_models, '\\\\nabla f(x)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1237c0b1",
   "metadata": {},
   "source": [
    "# Experiments with Wine:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "120cf0b4",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e244992",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Wine.csv')\n",
    "data['color'] = data['color'].apply(lambda x: 1 if x == 'red' else -1)\n",
    "X = data.drop(columns='color').to_numpy()\n",
    "y = data['color'].to_numpy()\n",
    "X = np.array(X, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad634eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5197, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16f336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "67bfac4f4aefe1c16f1836a62d55b6e6baa7aba1ac5ce70e93ee8e90eb4f073a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
