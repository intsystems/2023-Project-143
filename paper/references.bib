@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{jahani2021doubly,
  title={Doubly adaptive scaled algorithm for machine learning using second-order information},
  author={Jahani, Majid and Rusakov, Sergey and Shi, Zheng and Richt{\'a}rik, Peter and Mahoney, Michael W and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:2109.05198},
  year={2021}
}

@article{sadiev2022stochastic,
  title={Stochastic gradient methods with preconditioned updates},
  author={Sadiev, Abdurakhmon and Beznosikov, Aleksandr and Almansoori, Abdulla Jasem and Kamzolov, Dmitry and Tappenden, Rachael and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:2206.00285},
  year={2022}
}

@article{beznosikov2022scaled,
  title={On scaled methods for saddle point problems},
  author={Beznosikov, Aleksandr and Alanov, Aibek and Kovalev, Dmitry and Tak{\'a}{\v{c}}, Martin and Gasnikov, Alexander},
  journal={arXiv preprint arXiv:2206.08303},
  year={2022}
}

@article{stich2019unified,
  title={Unified optimal analysis of the (stochastic) gradient method},
  author={Stich, Sebastian U},
  journal={arXiv preprint arXiv:1907.04232},
  year={2019}
}