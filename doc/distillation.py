# -*- coding: utf-8 -*-
"""Dist_big_little_basedist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hsHl5xixfnrCzLXZKnjL3LTsYRigwpMF
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn

import torchvision
import torchvision.transforms as transforms

from tqdm.notebook import tqdm

import matplotlib.pyplot as plt
from IPython.display import clear_output

from math import ceil, sqrt

from torch.utils.data import Dataset
from torchvision import datasets

# On top of dataset for batching, shuffle, ...
from torch.utils.data import DataLoader

# Augumentations for images
from torchvision import transforms as tr


import torch.nn.functional as F

import numpy as np
import random

import warnings
warnings.filterwarnings("ignore")
# autoreload ALL modules in real time
# %load_ext autoreload
# %autoreload 2

#########
# FIXIT #
#########
from networks import ConvNet

from utils import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, ParamDiffAug, get_default_convnet_setting

!pip install kornia

# Section of setting seeds for reproducible results of training CNNs

# Set the seed for the Python random module
random.seed(0)

# Set the seed for NumPy's random number generator
np.random.seed(1)

# Set the seed for PyTorch's random number generator
torch.manual_seed(2)

# If training on GPU, set the seed for the GPU backend and CUDA library
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(3)

g = torch.Generator()
g.manual_seed(4)

def show_images(images, labels=None, title=None, transform=None, figsize=(12, 12)):
    fig = plt.figure(figsize=figsize, linewidth=5)
    grid_val = ceil(sqrt(len(images)))
    grid_specs = plt.GridSpec(grid_val, grid_val)
    
    for i, image in enumerate(images):
        ax = fig.add_subplot(grid_specs[i // grid_val, i % grid_val])
        ax.axis('off')
        
        if transform is not None:
            image = transform(image)
        
        if labels is not None:
            ax_title = labels[i]
        else:
            ax_title = '#{}'.format(i+1)
            
        ax.set_title(ax_title)
        ax.imshow(image, cmap='gray')
            
    if title:
        fig.suptitle(title, y=0.93, fontsize='xx-large')
    plt.show()

num_workers = 4     # maximum number of subprocces (check https://pytorch.org/docs/stable/data.html for more info)
batch_size = 64


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using {} device'.format(device))

"""## Load [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset from torchvision.datasets:"""

transform = transforms.Compose([
    transforms.ToTensor()
])

# download data
train_data = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, 
    transform=transform
)

test_data = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, 
    transform=transform
)

# create dataloaders for model
train_dataloader = torch.utils.data.DataLoader(
    train_data, shuffle=True, 
    batch_size=batch_size, num_workers=num_workers, generator=g
)

test_dataloader = torch.utils.data.DataLoader(
    test_data, shuffle=True, 
    batch_size=batch_size, num_workers=num_workers, generator=g
)

# show some images from MNIST
labels_map = {
    0: "Null",
    1: "One",
    2: "Two",
    3: "Three",
    4: "Four",
    5: "Five",
    6: "Six",
    7: "Seven",
    8: "Eight",
    9: "Nine",
}

N_samples = 16
images, labels = next(iter(train_dataloader))
show_images(
    images[:N_samples], 
    [labels_map[i.item()] for i in labels[:N_samples]], 
    transform=transforms.ToPILImage()
);

## Train-test loops

"""## Train-test loops"""

import IPython
from math import ceil


def train_loop(model, dataloader, loss_fn, optimizer, step=0.05, history_loss=None, history_acc=None):
    out = display(IPython.display.Pretty('Learning...'), display_id=True)

    size = len(dataloader.dataset) 
    len_size = len(str(size))
    batches = ceil(size / dataloader.batch_size) - 1
    
    train_acc, train_loss = [], []
    percentage = 0
    
    for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc="Batch #")):
        X, y = X.to(device), y.to(device)

        # forward pass
        y_pred = model(X)
        #print(X, y, y_pred)
        loss = loss_fn(y_pred, y)

        # backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # update statistics
        train_loss.append(loss.item())
        train_acc.append((y_pred.argmax(1) == y).sum().item() / len(X))
                
        # print info
        if batch / batches > percentage or batch == batches: 
            out.update(f'[{int(percentage * size)}/{size}] Loss: {loss:>8f}')
            percentage += step
        
    if history_loss is not None:
        history_loss.append(np.mean(train_loss))
    if history_acc is not None:
        history_acc.append(np.mean(train_acc))

    return {'train_loss': np.mean(train_loss), 'train_acc': np.mean(train_acc)}

def test_loop(model, dataloader, loss_fn, history_loss=None, history_acc=None):

    size = len(dataloader.dataset)
    test_loss, correct = 0, 0
    batches = ceil(size / dataloader.batch_size)

    val_loss, val_acc = [], []
    
    with torch.no_grad():
        for X, y in tqdm(dataloader, leave=False, desc="Batch #"):
            X, y = X.to(device), y.to(device)

            # evaluate
            y_pred = model(X)
            loss = loss_fn(y_pred, y)

            # check predictions
            test_loss += loss.item()
            correct += (y_pred.argmax(1) == y).sum().item()

            # update statistics
            val_loss.append(loss.item())
            val_acc.append((y_pred.argmax(1) == y).sum().item() / len(X))

    test_loss /= batches
    correct /= size
    
    print(f"Validation accuracy: {(100*correct):>0.1f}%, Validation loss: {test_loss:>8f} \n")

    if history_loss is not None:
        history_loss.append(np.mean(val_loss))
    if history_acc is not None:
        history_acc.append(np.mean(val_acc))
    
    return {'val_loss': np.mean(val_loss), 'val_acc': np.mean(val_acc)}

def distil_train_loop(large_model, distil_model, dataloader, loss_fn, optimizer, distil_weight, temp, step=0.05, history_loss=None, history_acc=None):
    out = display(IPython.display.Pretty('Learning...'), display_id=True)

    size = len(dataloader.dataset) 
    len_size = len(str(size))
    batches = ceil(size / dataloader.batch_size) - 1
    
    train_acc, train_loss = [], []
    percentage = 0

    large_model.eval()
    distil_model.train()

    for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc="Batch #")):
        X, y = X.to(device), y.to(device)

        # forward pass

        # backward pass
        optimizer.zero_grad()

        soft_label = F.softmax(large_model(X)/temp)

        y_pred = distil_model(X)

        soft_out = F.softmax(y_pred/temp)  

        loss = (1 - distil_weight) * F.cross_entropy(y_pred, y) + (distil_weight) * loss_fn(soft_label,soft_out)
        loss.backward()
        optimizer.step()
        
        # update statistics
        train_loss.append(loss.item())
        train_acc.append((y_pred.argmax(1) == y).sum().item() / len(X))
                
        # print info
        if batch / batches > percentage or batch == batches: 
            out.update(f'[{int(percentage * size)}/{size}] Loss: {loss:>8f}')
            percentage += step
        
    if history_loss is not None:
        history_loss.append(np.mean(train_loss))
    if history_acc is not None:
        history_acc.append(np.mean(train_acc))

    return {'train_loss': np.mean(train_loss), 'train_acc': np.mean(train_acc)}


def train_loop_dist(model, dataloader, loss_fn, optimizer, step=0.05, history_loss=None, history_acc=None):
    out = display(IPython.display.Pretty('Learning...'), display_id=True)

    size = len(dataloader.dataset) 
    len_size = len(str(size))
    batches = ceil(size / dataloader.batch_size) - 1

    train_acc, train_loss = [], []
    percentage = 0
    
    for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc="Batch #")):
        #print(X, y)
        X = X.to(device)
        y = y.to(device)


        X = DiffAugment(X, strategy = 'color_crop_cutout_flip_scale_rotate', param = dsa_params)
        # forward pass
        y_pred = model(X)
        #print(y_pred)
        #y_true = np.zeros(len(y_pred))
        #y_true[y[0]] = 1
        loss = loss_fn(y_pred, y)

        # backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # update statistics
        train_loss.append(loss.item())
        train_acc.append((y_pred.argmax(1) == y).sum().item() / len(X))
                
        # print info
        if batch / batches > percentage or batch == batches: 
            out.update(f'[{int(percentage * size)}/{size}] Loss: {loss:>8f}')
            percentage += step
        
    if history_loss is not None:
        history_loss.append(np.mean(train_loss))
    if history_acc is not None:
        history_acc.append(np.mean(train_acc))

    return {'train_loss': np.mean(train_loss), 'train_acc': np.mean(train_acc)}

def plot_learning_process(train_loss, train_acc, val_loss, val_acc):
    
    fig = plt.figure(figsize=(12, 4))
    
    ax1 = plt.subplot(121)
    ax1.set_title('loss by epoch')
    ax1.plot(np.arange(0, len(train_loss)) + 0.5, train_loss, label='train')
    ax1.plot(np.arange(0, len(val_loss)) + 1, val_loss, label='val')
    ax1.legend()
    ax1.grid()
    ax1.set_xlabel('epoch')
    ax1.set_ylabel('loss function')

    ax2 = plt.subplot(122)
    ax2.set_title('accuracy by epoch')
    ax2.plot(np.arange(0, len(train_acc)) + 0.5, train_acc, label='train')
    ax2.plot(np.arange(0, len(val_acc)) + 1, val_acc, label='val')
    ax2.legend()
    ax2.grid()
    ax2.set_xlabel('epoch')
    ax2.set_ylabel('accuracy')
    
    fig.tight_layout()
    plt.show()

"""#Models"""

import torch
import torch.nn as nn

class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        stride = (2, 2) if in_channels != out_channels else (1, 1)
        
        self.shortcut = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)
        
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.activation = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
    def forward(self, x):
        residual = self.shortcut(x)
        
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.activation(x)
        x = self.conv2(x)
        x = self.bn2(x)
        
        return x + residual
        
class ResNetLayer(nn.Module):
    '''
    This class should be implemented similarly to layer from the pytorch implementation.

    To implement the layer, you will need to create two ResidualBlocks inside.
    Determining the appropriate dimensions is up to you.
    '''

    def __init__(self, in_channels, out_channels):
        '''
        The layer must have the following field declared:
            *self.blocks
        '''

        super().__init__()

        self.blocks = nn.Sequential(
            ResidualBlock(in_channels, out_channels),
            ResidualBlock(out_channels, out_channels)
        )

    def forward(self, x):
        '''
        Note that blocks must be packed to make forward work in its original form.
        '''
        x = self.blocks(x)
        return x

class ResNet18(nn.Module):
     '''
     Finally, this class should consist of three main components:
       1. Four preparatory layers
       2. A set of internal ResNetLayers
       3. Final classifier

     Hint! In order for the network to process images from CIFAR10, you should replace the parameters
           of the first convolutional layer on kernel_size=(3, 3), stride=(1, 1) and padding=(1, 1).
     '''

     def __init__(self, in_channels=3, n_classes=10):
         '''
         The class must have the following fields declared:
             *self.conv1
             *self.bn1
             *self.activation
             *self.maxpool
             *self.layers
             *self.avgpool
             *self.flatten
             *self.fc

         A different grouping of parameters is allowed that does not violate the idea of the network architecture.
         '''

         super().__init__()

         self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(64)
         self.activation = nn.ReLU(inplace=True)
         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

         self.layer1 = ResNetLayer(64, 64)
         self.layer2 = ResNetLayer(64, 128)
         self.layer3 = ResNetLayer(128, 256)
         self.layer4 = ResNetLayer(256, 512)

         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
         self.flatten = nn.Flatten()
         self.fc = nn.Linear(512, n_classes)

     def forward(self, x):

         x = self.conv1(x)
         x = self.bn1(x)
         x = self.activation(x)
         x = self.maxpool(x)

         x = self.layer1(x)
         x = self.layer2(x)
         x = self.layer3(x)
         x = self.layer4(x)

         x = self.avgpool(x)
         x = self.flatten(x)
         x = self.fc(x)

         return x

import torch
import torch.nn as nn


class ResidualBlock50(nn.Module):
     
     def __init__(self, in_channels, out_channels, stride=1):
         super(ResidualBlock50, self).__init__()
         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(out_channels)
         self.relu = nn.ReLU(inplace=True)
         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
         self.bn2 = nn.BatchNorm2d(out_channels)
         self.shortcut = nn.Sequential()
         if stride != 1 or in_channels != out_channels:
             self.shortcut = nn.Sequential(
                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                 nn.BatchNorm2d(out_channels)
             )

     def forward(self, x):
         residual = self.shortcut(x)
         
         x = self.conv1(x)
         x = self.bn1(x)
         x = self.relu(x)
         x = self.conv2(x)
         x = self.bn2(x)
         x += residual
         x = self.relu(x)

         return x


class ResNetLayer50(nn.Module):
     
     def __init__(self, in_channels, out_channels, n_blocks, stride=1):
         super(ResNetLayer50, self).__init__()
         self.blocks = nn.Sequential()
         self.blocks.add_module("block0", ResidualBlock50(in_channels, out_channels, stride=stride))
         for block_idx in range(1, n_blocks):
             self.blocks.add_module(f"block{block_idx}", ResidualBlock50(out_channels, out_channels))

     def forward(self, x):
         x = self.blocks(x)
         return x


class ResNet50(nn.Module):
     
     def __init__(self, in_channels=3, n_classes=10):
         super(ResNet50, self).__init__()
         self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(64)
         self.relu = nn.ReLU(inplace=True)
         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

         self.layer1 = ResNetLayer50(in_channels=64, out_channels=64, n_blocks=3)
         self.layer2 = ResNetLayer50(in_channels=64, out_channels=128, n_blocks=4, stride=2)
         self.layer3 = ResNetLayer50(in_channels=128, out_channels=256, n_blocks=6, stride=2)
         self.layer4 = ResNetLayer50(in_channels=256, out_channels=512, n_blocks=3, stride=2)

         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
         self.flatten = nn.Flatten()
         self.fc = nn.Linear(512, n_classes)

     def forward(self, x):
         x = self.conv1(x)
         x = self.bn1(x)
         x = self.relu(x)
         x = self.maxpool(x)

         x = self.layer1(x)
         x = self.layer2(x)
         x = self.layer3(x)
         x = self.layer4(x)

         x = self.avgpool(x)
         x = self.flatten(x)
         x = self.fc(x)

         return x



#torchvision.models.resnet18() # uncomment this to see a Hint 0!
#ResNet18()

"""## Train large model"""

big_model = ResNet50(in_channels = 3)

if torch.cuda.is_available():
    big_model.cuda()

# loss_fn, optimizer and number of epochs are required
loss_fn_teacher = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(big_model.parameters(), lr=0.001, momentum=0.9)

# Define the number of epochs
epochs = 6

train_loss, train_acc = [], []
val_loss, val_acc = [], []
# Train the model
for epoch in tqdm(range(epochs)):
    print(f"Epoch {epoch+1}\n-------------------------------")
    # training loop
    train_results = train_loop(big_model, train_dataloader, loss_fn_teacher, optimizer)
    train_loss.append(train_results['train_loss'])
    train_acc.append(train_results['train_acc'])
    print(f"Train loss: {train_loss[-1]:.4f}, Train accuracy: {train_acc[-1]*100:.2f}%")

    # validation loop
    val_results = test_loop(big_model, test_dataloader, loss_fn_teacher)
    val_loss.append(val_results['val_loss'])
    val_acc.append(val_results['val_acc'])
    print(f"Validation loss: {val_loss[-1]:.4f}, Validation accuracy: {val_acc[-1]*100:.2f}%\n")

print("Finished Training")

plot_learning_process(train_loss, train_acc, val_loss, val_acc)

#model = ResNet50(in_channels = 3)
net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()
channel = 3
num_classes = 10
little = ConvNet(channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling)

if torch.cuda.is_available():
    little.cuda()

# loss_fn, optimizer and number of epochs are required
loss_fn_teacher = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(little.parameters(), lr=0.001, momentum=0.9)

# Define the number of epochs
epochs = 8

train_loss, train_acc = [], []
val_loss, val_acc = [], []
# Train the model
for epoch in tqdm(range(epochs)):
    print(f"Epoch {epoch+1}\n-------------------------------")
    # training loop
    train_results = train_loop(little, train_dataloader, loss_fn_teacher, optimizer)
    train_loss.append(train_results['train_loss'])
    train_acc.append(train_results['train_acc'])
    print(f"Train loss: {train_loss[-1]:.4f}, Train accuracy: {train_acc[-1]*100:.2f}%")

    # validation loop
    val_results = test_loop(little, test_dataloader, loss_fn_teacher)
    val_loss.append(val_results['val_loss'])
    val_acc.append(val_results['val_acc'])
    print(f"Validation loss: {val_loss[-1]:.4f}, Validation accuracy: {val_acc[-1]*100:.2f}%\n")

print("Finished Training")

plot_learning_process(train_loss, train_acc, val_loss, val_acc)


distil_weights = np.array([0.3, 0.7])
temps = np.array([0.5, 1, 2])

# Define the number of epochs
epochs = 9
for temp in temps:
    for dist_w in distil_weights:
        distil_model = ConvNet(channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling)

        if torch.cuda.is_available():
            distil_model.cuda()

        loss_fn = nn.KLDivLoss()
        optimizer = torch.optim.SGD(distil_model.parameters(), lr=0.001, momentum=0.9)

        train_loss, train_acc = [], []
        val_loss, val_acc = [], []
        print(f'Distill weight :{dist_w}, temp :{temp}')
# Train the model
        for epoch in tqdm(range(epochs)):
            print(f"Epoch {epoch+1}\n-------------------------------")
    # training loop
            train_results = distil_train_loop(big_model, distil_model, train_dataloader, loss_fn, optimizer, dist_w, temp)
            train_loss.append(train_results['train_loss'])
            train_acc.append(train_results['train_acc'])
            print(f"Train loss: {train_loss[-1]:.4f}, Train accuracy: {train_acc[-1]*100:.2f}%")

    # validation loop
            val_results = test_loop(distil_model, test_dataloader, loss_fn_teacher)
            val_loss.append(val_results['val_loss'])
            val_acc.append(val_results['val_acc'])
            print(f"Validation loss: {val_loss[-1]:.4f}, Validation accuracy: {val_acc[-1]*100:.2f}%\n")
        plot_learning_process(train_loss, train_acc, val_loss, val_acc)

print("Finished Training")

plot_learning_process(train_loss, train_acc, val_loss, val_acc)

"""# Создадим класс своего дистиллированного маленького датасета и даталоадер"""

import os
from PIL import Image
import cv2
from torchvision import transforms as tr


class MyDataset(Dataset):
    labels_map = {
        0: "airplane",
        1: "automobile",
        2: "bird",
        3: "cat",
        4: "deer",
        5: "dog",
        6: "frog",
        7: "horse",
        8: "ship",
        9: "truck",
    }

    def __init__(self, imgs_path, transform = None):
        super(MyDataset).__init__()

        self.imgs_path = imgs_path
        self.transform = tr.Compose(
            [
                tr.ToPILImage(),
                tr.Resize((32, 32)),
                tr.ToTensor()
            ]
        )  

        self.imgs_paths = list(sorted([os.path.join(imgs_path, f) for f in os.listdir(imgs_path)]))

        self.idxs = [i for i in range(0, self.__len__())]
        self.pics = [i for i in range(0, self.__len__())] # по картинке возвращает ее класс
        print(self.imgs_paths)
        for i in range(0, self.__len__()):

            dir = self.imgs_paths[i]
            image = cv2.imread(os.path.join(dir))
        # преобразуем изображение в формат RGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            #image = Image.open(dir).convert('RGB')
            
            if self.transform:
                image = self.transform(image)

            #self.pics[i] = self.labels_map[int(dir[-6])]
            self.pics[i] = int(dir[-6])
            self.idxs[i] = image

        # принимает индекс картинки, вернуть картинку и верную метку
        
    def __getitem__(self, idx):
        return self.transform(self.idxs[idx]), self.pics[idx]
        
    def __len__(self):
        return len(self.imgs_paths)

download_dir = '/content/solo'

dataset = MyDataset(download_dir, transform = tr.Resize((32, 32)))

dataloader = torch.utils.data.DataLoader(
    dataset = dataset, shuffle=True, 
    batch_size=1, num_workers=num_workers, generator=g
)

dsa_params = ParamDiffAug()

#model = ResNet50(in_channels = 3)
net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()
channel = 3
num_classes = 10
model = ConvNet(channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling)

if torch.cuda.is_available():
    model.cuda()

"""## дистил картинки и конвнет"""

# loss_fn, optimizer and number of epochs are required
loss_fn_teacher = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Define the number of epochs
epochs = 40

train_loss, train_acc = [], []
val_loss, val_acc = [], []
# Train the model
for epoch in tqdm(range(epochs)):
    print(f"Epoch {epoch+1}\n-------------------------------")
    # training loop
    train_results = train_loop_dist(model, dataloader, loss_fn_teacher, optimizer)
    train_loss.append(train_results['train_loss'])
    train_acc.append(train_results['train_acc'])
    print(f"Train loss: {train_loss[-1]:.4f}, Train accuracy: {train_acc[-1]*100:.2f}%")

    # validation loop
    val_results = test_loop(model, test_dataloader, loss_fn_teacher)
    val_loss.append(val_results['val_loss'])
    val_acc.append(val_results['val_acc'])
    print(f"Validation loss: {val_loss[-1]:.4f}, Validation accuracy: {val_acc[-1]*100:.2f}%\n")
    plot_learning_process(train_loss, train_acc, val_loss, val_acc)


print("Finished Training")

"""Супердистиллированные"""



download_dir = '/content/2_03/2_03'

dataset = MyDataset(download_dir, transform = tr.Resize((32, 32)))

dataloader = torch.utils.data.DataLoader(
    dataset = dataset, shuffle=True, 
    batch_size=1, num_workers=num_workers, generator=g
)

test_data = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, 
    transform=transform
)

test_dataloader = torch.utils.data.DataLoader(
    test_data, shuffle=True, 
    batch_size=64, num_workers=num_workers, generator=g
)

dsa_params = ParamDiffAug()

#model = ResNet50(in_channels = 3)
net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()
channel = 3
num_classes = 10
model = ConvNet(channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling)

if torch.cuda.is_available():
    model.cuda()
# loss_fn, optimizer and number of epochs are required
loss_fn_teacher = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Define the number of epochs
epochs = 40

train_loss, train_acc = [], []
val_loss, val_acc = [], []
# Train the model
for epoch in tqdm(range(epochs)):
    print(f"Epoch {epoch+1}\n-------------------------------")
    # training loop
    train_results = train_loop_dist(model, dataloader, loss_fn_teacher, optimizer)
    train_loss.append(train_results['train_loss'])
    train_acc.append(train_results['train_acc'])
    print(f"Train loss: {train_loss[-1]:.4f}, Train accuracy: {train_acc[-1]*100:.2f}%")

    # validation loop
    val_results = test_loop(model, test_dataloader, loss_fn_teacher)
    val_loss.append(val_results['val_loss'])
    val_acc.append(val_results['val_acc'])
    print(f"Validation loss: {val_loss[-1]:.4f}, Validation accuracy: {val_acc[-1]*100:.2f}%\n")
    plot_learning_process(train_loss, train_acc, val_loss, val_acc)


print("Finished Training")
